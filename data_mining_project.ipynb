{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e529149",
   "metadata": {},
   "source": [
    "## 1) Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fc919",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "**Dataset:** Student Performance Dataset (Portuguese or Math course)\n",
    "\n",
    "**Objective:** Predict student academic success (pass/fail) based on demographic, social, and school-related features\n",
    "\n",
    "**Methods:**\n",
    "1. **Exploratory Data Analysis (EDA)**: Analyze distributions, correlations, and class balance\n",
    "2. **Data Preprocessing**: Handle missing values, encode categorical variables, create target variable\n",
    "3. **Supervised Learning**: Train and evaluate three classification models\n",
    "   - Logistic Regression\n",
    "   - Random Forest\n",
    "   - Gradient Boosting\n",
    "4. **Model Evaluation**: Use accuracy, precision, recall, F1-score, ROC AUC, and cross-validation\n",
    "5. **Unsupervised Learning**: K-Means clustering to identify student segments\n",
    "6. **Association Rule Mining**: Discover frequent patterns in student characteristics\n",
    "\n",
    "**Target Variable:** Binary classification - Pass (G3 >= 10) or Fail (G3 < 10)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4e9516",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Read the dataset into a pandas DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Update this path if needed (using raw strings to handle backslashes correctly)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Read the dataset into a pandas DataFrame\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Update this path if needed (using raw strings to handle backslashes correctly)\n",
    "if os.path.exists(r'C:\\Users\\Acer\\Downloads\\Group Projrct\\student-por.csv'):\n",
    "    df = pd.read_csv(r'C:\\Users\\Acer\\Downloads\\Group Projrct\\student-por.csv', sep=';')\n",
    "elif os.path.exists(r'C:\\Users\\Acer\\Downloads\\Group Projrct\\student-mat.csv'):\n",
    "    df = pd.read_csv(r'C:\\Users\\Acer\\Downloads\\Group Projrct\\student-mat.csv', sep=';')\n",
    "else:\n",
    "    # Try to find any csv in working dir\n",
    "    csvs = [f for f in os.listdir('.') if f.lower().endswith('.csv')]\n",
    "    if csvs:\n",
    "        df = pd.read_csv(csvs[0], sep=';')\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "        print('No CSV found in working directory. Please upload or set the correct path.')\n",
    "\n",
    "print('Data shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d14595",
   "metadata": {},
   "source": [
    "## 2) Exploratory Data Analysis (EDA)\n",
    "Inspect distributions, missing values, correlations, and class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ddd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print('\\n--- Dataset Info ---')\n",
    "display(df.info())\n",
    "\n",
    "print('\\n--- Descriptive Statistics (numeric) ---')\n",
    "display(df.describe())\n",
    "\n",
    "print('\\n--- Missing Values ---')\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    display(missing[missing > 0])\n",
    "else:\n",
    "    print('No missing values found!')\n",
    "\n",
    "# Plot distributions for numeric features (one chart per numeric column)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f'\\nPlotting distributions for {len(num_cols)} numeric features...')\n",
    "for col in num_cols[:15]:  # Limit to first 15 to avoid too many plots\n",
    "    plt.figure(figsize=(6,2.5))\n",
    "    plt.hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "    plt.title(f'Distribution: {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Plot categorical value counts for top categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()\n",
    "print(f'\\nPlotting value counts for {min(len(cat_cols), 6)} categorical features...')\n",
    "for col in cat_cols[:6]:\n",
    "    plt.figure(figsize=(6,2.5))\n",
    "    df[col].value_counts().plot(kind='bar', edgecolor='black', alpha=0.7)\n",
    "    plt.title(f'Value Counts: {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numeric features\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "if len(numeric_df.columns) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = numeric_df.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix of Numeric Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show features most correlated with G3 (final grade)\n",
    "    if 'G3' in correlation_matrix.columns:\n",
    "        print('\\nFeatures most correlated with Final Grade (G3):')\n",
    "        g3_corr = correlation_matrix['G3'].sort_values(ascending=False)\n",
    "        print(g3_corr.to_string())\n",
    "else:\n",
    "    print('Not enough numeric columns for correlation analysis.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5688cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance for target variable (G3 grades)\n",
    "if 'G3' in df.columns:\n",
    "    # Show distribution of final grades with new pass/fail threshold\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['G3'], bins=21, edgecolor='black')\n",
    "    plt.xlabel('Final Grade (G3)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Final Grades')\n",
    "    plt.axvline(x=10, color='r', linestyle='--', label='Pass Threshold (G3=10)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    pass_count = (df['G3'] >= 10).sum()\n",
    "    fail_count = (df['G3'] < 10).sum()\n",
    "    plt.bar(['Fail (G3<10)', 'Pass (G3>=10)'], [fail_count, pass_count], color=['#ff6b6b', '#4ecdc4'])\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Class Balance: Pass vs Fail')\n",
    "    for i, v in enumerate([fail_count, pass_count]):\n",
    "        plt.text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'Pass rate: {pass_count}/{len(df)} = {pass_count/len(df)*100:.1f}%')\n",
    "    print(f'Fail rate: {fail_count}/{len(df)} = {fail_count/len(df)*100:.1f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967afacb",
   "metadata": {},
   "source": [
    "## 3) Data Cleaning & Preprocessing\n",
    "Handle missing values, encode categorical variables, and create target variable.\n",
    "\n",
    "**Example target:** predict final grade pass/fail (G3 >= 10 -> pass). Adjust to your project's objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example preprocessing pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Make a copy\n",
    "data = df.copy()\n",
    "\n",
    "# Example: create binary target 'pass' from final grade column G3 if present\n",
    "if 'G3' in data.columns:\n",
    "    data['pass'] = (data['G3'] >= 10).astype(int)\n",
    "    target_col = 'pass'\n",
    "else:\n",
    "    # If no numeric grade present, user should set target manually\n",
    "    print('No G3 column found. Please define your target_col manually.')\n",
    "    target_col = None\n",
    "\n",
    "# Drop columns unlikely to be helpful (example: drop G1 and G2 to avoid leakage)\n",
    "# G1 and G2 are period grades that directly predict G3, so excluding them makes the problem more realistic\n",
    "drop_cols = ['G1', 'G2']\n",
    "for c in drop_cols:\n",
    "    if c in data.columns:\n",
    "        data.drop(columns=c, inplace=True)\n",
    "\n",
    "# Separate features and target\n",
    "if target_col:\n",
    "    X = data.drop(columns=[target_col])\n",
    "    y = data[target_col]\n",
    "else:\n",
    "    X = data.copy()\n",
    "    y = None\n",
    "\n",
    "# Simple handling: numeric columns fillna with median, categorical with mode, one-hot encode categoricals\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "preproc = ColumnTransformer([('num', num_pipe, num_cols),\n",
    "                             ('cat', cat_pipe, cat_cols)], remainder='drop')\n",
    "\n",
    "# Note: For supervised learning, preproc will be fit on training data only (see Cell 11)\n",
    "# For unsupervised learning (clustering), we'll fit on the full dataset\n",
    "print('Feature columns identified:')\n",
    "print(f'  - Numeric: {len(num_cols)} columns')\n",
    "print(f'  - Categorical: {len(cat_cols)} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract column names after OneHotEncoder for interpretability\n",
    "# Fit preproc on full X temporarily just to get feature names\n",
    "try:\n",
    "    preproc_temp = ColumnTransformer([('num', num_pipe, num_cols),\n",
    "                                      ('cat', cat_pipe, cat_cols)], remainder='drop')\n",
    "    preproc_temp.fit(X)\n",
    "    \n",
    "    ohe = None\n",
    "    for name, trans, cols in preproc_temp.transformers_:\n",
    "        if name == 'cat':\n",
    "            ohe = trans.named_steps['onehot']\n",
    "            cat_in_cols = cols\n",
    "    feature_names = []\n",
    "    # numeric names\n",
    "    feature_names.extend(num_cols)\n",
    "    # onehot names\n",
    "    if ohe is not None:\n",
    "        ohe_names = ohe.get_feature_names_out(cat_in_cols)\n",
    "        feature_names.extend(list(ohe_names))\n",
    "    print('Number of features after preprocessing:', len(feature_names))\n",
    "except Exception as e:\n",
    "    feature_names = None\n",
    "    print('Could not extract feature names automatically.', e)\n",
    "\n",
    "feature_names[:50] if feature_names else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f07d5",
   "metadata": {},
   "source": [
    "## 4) Predictive Modeling (Supervised)\n",
    "We build three models: Logistic Regression, Random Forest, and Gradient Boosting. Use cross-validation and provide performance metrics (accuracy, precision, recall, F1, ROC AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5dea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling: train/test split and basic training pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Only proceed if we have a target\n",
    "if y is None:\n",
    "    print('No target variable defined. Define y to proceed with supervised modeling.')\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    # Fit preprocessor ONLY on training data to avoid data leakage\n",
    "    X_train_pre = preproc.fit_transform(X_train)\n",
    "    X_test_pre = preproc.transform(X_test)\n",
    "\n",
    "    models = {\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        'GradientBoosting': GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_pre, y_train)\n",
    "        y_pred = model.predict(X_test_pre)\n",
    "        y_proba = model.predict_proba(X_test_pre)[:,1] if hasattr(model, 'predict_proba') else None\n",
    "        res = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "            'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        }\n",
    "        if y_proba is not None:\n",
    "            res['roc_auc'] = roc_auc_score(y_test, y_proba)\n",
    "        results[name] = res\n",
    "        print(f'--- {name} ---')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    print('\\nSummary results:')\n",
    "    import pandas as pd\n",
    "    display(pd.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance comparison\n",
    "if y is not None and len(results) > 0:\n",
    "    import pandas as pd\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    \n",
    "    # Plot metrics comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        if metric in results_df.columns:\n",
    "            results_df[metric].plot(kind='bar', ax=ax, color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "            ax.set_title(f'{metric.capitalize()} by Model')\n",
    "            ax.set_ylabel(metric.capitalize())\n",
    "            ax.set_xlabel('Model')\n",
    "            ax.set_ylim([0, 1])\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            ax.set_xticklabels(results_df.index, rotation=45, ha='right')\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for i, v in enumerate(results_df[metric]):\n",
    "                ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display ROC AUC comparison if available\n",
    "    if 'roc_auc' in results_df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        results_df['roc_auc'].plot(kind='bar', color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "        plt.title('ROC AUC Score by Model')\n",
    "        plt.ylabel('ROC AUC')\n",
    "        plt.xlabel('Model')\n",
    "        plt.ylim([0, 1])\n",
    "        plt.grid(True, alpha=0.3, axis='y')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, v in enumerate(results_df['roc_auc']):\n",
    "            plt.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation (Stratified K-Fold) for each model\n",
    "# Use Pipeline to avoid data leakage - preprocessor fits only on training folds\n",
    "if y is not None:\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_results = {}\n",
    "    \n",
    "    # Create pipelines for each model to ensure proper cross-validation\n",
    "    for name, model in models.items():\n",
    "        # Create a fresh preprocessor for CV to avoid leakage\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        num_pipe_cv = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "        cat_pipe_cv = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                             ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "        preproc_cv = ColumnTransformer([('num', num_pipe_cv, num_cols),\n",
    "                                     ('cat', cat_pipe_cv, cat_cols)], remainder='drop')\n",
    "        \n",
    "        # Create pipeline with preprocessing and model\n",
    "        pipeline = Pipeline([('preprocess', preproc_cv), ('classifier', model)])\n",
    "        scores = cross_val_score(pipeline, X, y, cv=skf, scoring='f1')\n",
    "        cv_results[name] = scores\n",
    "    print('Cross-val F1 scores:')\n",
    "    display(pd.DataFrame(cv_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db54178",
   "metadata": {},
   "source": [
    "### Feature importance (for tree-based models)\n",
    "Show top features from RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42e6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances from RandomForest\n",
    "import numpy as np\n",
    "if 'RandomForest' in models and feature_names is not None:\n",
    "    rf = models['RandomForest']\n",
    "    importances = rf.feature_importances_\n",
    "    idx = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print('Top 20 Most Important Features:')\n",
    "    print('-' * 50)\n",
    "    for i, feat_idx in enumerate(idx[:20], 1):\n",
    "        print(f'{i:2d}. {feature_names[feat_idx]:40s} {importances[feat_idx]:.4f}')\n",
    "    \n",
    "    # Visualize top features\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_n = 15\n",
    "    top_idx = idx[:top_n]\n",
    "    plt.barh(range(top_n), importances[top_idx])\n",
    "    plt.yticks(range(top_n), [feature_names[i] for i in top_idx])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 15 Feature Importances (Random Forest)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Feature names not available or RandomForest not trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec00e416",
   "metadata": {},
   "source": [
    "## 5) Unsupervised Modeling\n",
    "### 5.1 K-Means clustering\n",
    "Cluster students and inspect cluster characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans clustering on preprocessed features (use PCA to reduce dimensionality for visualization)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For unsupervised learning, fit preprocessor on full dataset (no data leakage concerns)\n",
    "preproc_unsup = ColumnTransformer([('num', num_pipe, num_cols),\n",
    "                                   ('cat', cat_pipe, cat_cols)], remainder='drop')\n",
    "X_full_pre = preproc_unsup.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_full_pre)\n",
    "\n",
    "# Choose k with simple elbow method\n",
    "inertia = []\n",
    "K = range(2,8)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_full_pre)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(list(K), inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal K Selection')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Fit k=3 as example (adjust based on elbow plot)\n",
    "k = 3\n",
    "km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "clusters = km.fit_predict(X_full_pre)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=clusters, cmap='viridis', alpha=0.6)\n",
    "plt.title('PCA Projection Colored by Cluster')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Attach cluster labels back to original DataFrame (first N rows aligned)\n",
    "df_clustered = X.copy()\n",
    "df_clustered = df_clustered.reset_index(drop=True)\n",
    "df_clustered['cluster'] = clusters\n",
    "df_clustered['pca1'] = X_pca[:,0]\n",
    "df_clustered['pca2'] = X_pca[:,1]\n",
    "\n",
    "# Show cluster characteristics (numeric columns only)\n",
    "print('\\nCluster Characteristics (mean values for numeric features):')\n",
    "numeric_cols_clustered = df_clustered.select_dtypes(include=[np.number]).columns.tolist()\n",
    "display(df_clustered.groupby('cluster')[numeric_cols_clustered].mean().T)\n",
    "\n",
    "# Show cluster sizes\n",
    "print('\\nCluster Sizes:')\n",
    "cluster_counts = df_clustered['cluster'].value_counts().sort_index()\n",
    "display(cluster_counts)\n",
    "\n",
    "# For categorical columns, show most common value per cluster\n",
    "print('\\nMost Common Categorical Values per Cluster:')\n",
    "cat_cols_clustered = df_clustered.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if len(cat_cols_clustered) > 0:\n",
    "    for col in cat_cols_clustered[:5]:  # Show first 5 categorical columns\n",
    "        print(f'\\n{col}:')\n",
    "        display(df_clustered.groupby('cluster')[col].agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c72c19",
   "metadata": {},
   "source": [
    "### 5.2 Association Rule Mining (optional)\n",
    "Find frequent itemsets and association rules from categorical features using mlxtend.\n",
    "\n",
    "Note: mlxtend must be installed in your environment. If running on Colab, uncomment the pip install line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f176c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association rules using mlxtend\n",
    "# Uncomment to install: !pip install mlxtend\n",
    "\n",
    "try:\n",
    "    from mlxtend.preprocessing import TransactionEncoder\n",
    "    from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "    # Prepare transactions: take categorical columns and treat each row as a transaction of 'col=value'\n",
    "    cat_for_rules = cat_cols[:8] if len(cat_cols) >= 1 else []\n",
    "    transactions = []\n",
    "    \n",
    "    if len(cat_for_rules) > 0:\n",
    "        for _, row in df[cat_for_rules].iterrows():\n",
    "            # Only include non-null values\n",
    "            tx = [f'{col}={row[col]}' for col in cat_for_rules if pd.notna(row[col])]\n",
    "            transactions.append(tx)\n",
    "\n",
    "        te = TransactionEncoder()\n",
    "        te_ary = te.fit(transactions).transform(transactions)\n",
    "        df_tf = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "        # Find frequent itemsets\n",
    "        freq = apriori(df_tf, min_support=0.05, use_colnames=True)\n",
    "        \n",
    "        if len(freq) > 0:\n",
    "            print('Top 20 Frequent Itemsets:')\n",
    "            display(freq.sort_values('support', ascending=False).head(20))\n",
    "            \n",
    "            # Generate association rules\n",
    "            if len(freq) > 1:\n",
    "                rules = association_rules(freq, metric='lift', min_threshold=1.2)\n",
    "                if len(rules) > 0:\n",
    "                    print('\\nTop 20 Association Rules by Lift:')\n",
    "                    display(rules.sort_values('lift', ascending=False).head(20))\n",
    "                else:\n",
    "                    print('No association rules found with the given threshold.')\n",
    "            else:\n",
    "                print('Not enough frequent itemsets to generate rules.')\n",
    "        else:\n",
    "            print('No frequent itemsets found with min_support=0.05')\n",
    "    else:\n",
    "        print('Not enough categorical columns for association rules.')\n",
    "        \n",
    "except ImportError:\n",
    "    print('mlxtend not installed. Run: pip install mlxtend')\n",
    "except Exception as e:\n",
    "    print(f'Error in association rule mining: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f687e1",
   "metadata": {},
   "source": [
    "## 6) Visualizations & Reporting\n",
    "Create concise, publication-ready visuals for the report and slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef947743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations: ROC curves and Confusion Matrix\n",
    "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n",
    "\n",
    "if y is not None and len(results) > 0:\n",
    "    # Plot ROC curves for all models\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for name, model in models.items():\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_proba = model.predict_proba(X_test_pre)[:,1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    plt.plot([0,1], [0,1], 'k--', label='Random Classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves - Model Comparison')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Find best model by ROC AUC\n",
    "    best_model_name = None\n",
    "    best_auc = -1\n",
    "    for name, res in results.items():\n",
    "        if 'roc_auc' in res and res['roc_auc'] > best_auc:\n",
    "            best_auc = res['roc_auc']\n",
    "            best_model_name = name\n",
    "    \n",
    "    # Plot confusion matrix for best model\n",
    "    if best_model_name:\n",
    "        print(f'\\nConfusion Matrix for Best Model: {best_model_name}')\n",
    "        model = models[best_model_name]\n",
    "        y_pred = model.predict(X_test_pre)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "        ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax, cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print('No models trained to visualize.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd395d47",
   "metadata": {},
   "source": [
    "## 7) Save cleaned/processed dataset\n",
    "Save the cleaned dataset and any intermediate artifacts to disk for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned DataFrame and clustered results\n",
    "if not df.empty:\n",
    "    cleaned_path = 'cleaned_student_data.csv'\n",
    "    df.to_csv(cleaned_path, index=False)\n",
    "    print('Saved cleaned data to', cleaned_path)\n",
    "    try:\n",
    "        df_clustered.to_csv('clustered_student_data.csv', index=False)\n",
    "        print('Saved clustered data to clustered_student_data.csv')\n",
    "    except Exception:\n",
    "        pass\n",
    "else:\n",
    "    print('No dataframe to save.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67383999",
   "metadata": {},
   "source": [
    "## 8) Conclusion & Next Steps\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**Model Performance:**\n",
    "- Compared three classification models: Logistic Regression, Random Forest, and Gradient Boosting\n",
    "- Evaluated using multiple metrics: accuracy, precision, recall, F1-score, and ROC AUC\n",
    "- Cross-validation used to ensure robust performance estimates and avoid overfitting\n",
    "\n",
    "**Feature Importance:**\n",
    "- Random Forest feature importances reveal which factors most strongly predict student success\n",
    "- Use these insights to identify at-risk students early and target interventions\n",
    "\n",
    "**Student Segmentation:**\n",
    "- K-Means clustering identified distinct student groups based on demographic and behavioral characteristics\n",
    "- Clusters can inform personalized intervention strategies\n",
    "\n",
    "**Association Rules:**\n",
    "- Discovered patterns in categorical features that frequently co-occur\n",
    "- Can reveal behavioral patterns associated with academic performance\n",
    "\n",
    "### Recommendations for Interventions\n",
    "\n",
    "1. **Early Warning System**: Use predictive models to identify students at risk of failing\n",
    "2. **Targeted Tutoring**: Focus resources on students with low study time, high absences, or past failures\n",
    "3. **Parent Engagement**: Reach out to families of at-risk students, especially where family support is low\n",
    "4. **Behavioral Interventions**: Address factors like excessive going out, alcohol consumption, and low study time\n",
    "\n",
    "### Model Improvements & Next Steps\n",
    "\n",
    "1. **Handle Class Imbalance**: If pass/fail classes are imbalanced, try:\n",
    "   - SMOTE (Synthetic Minority Over-sampling)\n",
    "   - Class weights in model training\n",
    "   - Stratified sampling\n",
    "\n",
    "2. **Feature Engineering**: Create interaction features or polynomial features\n",
    "3. **Hyperparameter Tuning**: Use GridSearchCV or RandomizedSearchCV for optimal parameters\n",
    "4. **Ensemble Methods**: Combine multiple models for potentially better performance\n",
    "5. **Fairness Analysis**: Evaluate model performance across demographic subgroups (sex, age, school)\n",
    "6. **Temporal Analysis**: If longitudinal data available, track student progress over time\n",
    "\n",
    "### Ethical Considerations\n",
    "\n",
    "- Ensure model predictions don't perpetuate bias against certain demographic groups\n",
    "- Use predictions to help students, not punish them\n",
    "- Maintain student privacy and data security\n",
    "- Validate model decisions with educators before taking action\n",
    "\n",
    "---\n",
    "\n",
    "*This analysis provides a comprehensive data mining approach to student performance prediction using supervised learning (classification), unsupervised learning (clustering), and association rule mining.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
